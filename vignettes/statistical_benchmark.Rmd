---
title: "Statistical Benchmarks: Monte Carlo Simulations"
output: 
  rmarkdown::html_vignette:
    css: style.css
    toc: true
    toc_depth: 2
vignette: >
  %\VignetteIndexEntry{Statistical Benchmarks: Monte Carlo Simulations}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  warning = FALSE,
  message = FALSE
)
```

This guide presents a statistical validation of the wavelets implemented in `rLifting`.
The central focus is to evaluate the efficacy of the `rLifting`smoother's compared to **Offline (Batch)** methods.

## Experimental Methodology

To ensure robustness, we performed a Monte Carlo Simulation with the following characteristics:

1.  **Signals:** We used standard benchmark functions: `bumps` (abrupt transients), `doppler` (variable frequency), and `heavisine` (jumps and waves).

2.  **Data:** Generated N=1000 curves of T=2048 points for each function, with additive Gaussian noise (Ïƒ=0.2).

3.  **Configuration:** Both methods (Offline and Causal) were set to **3 decomposition levels** (L=3).
    This ensures a fair comparison of filtering capacity by isolating the effect of causality.

4.  **Grid:** We evaluated all combinations of wavelets (`haar`, `db2`, `cdf5/3`, `cdf9/7`, `dd4`) and extension methods.

Efficacy was evaluated based on recovered signal quality (**SNR**) and global precision (**RMSE**).

## Results

```{r}
library(rLifting)
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)

# Standard visual config
theme_set(theme_bw() + theme(legend.position = "top"))

cols_mode = c(
  "Causal" = "firebrick", 
  "Offline" = "royalblue", 
  "Baseline" = "black"
  )

# Load pre-computed data or run a demo if missing (CRAN compliance)
result_file = "sim_results_N1000.rds"

if (file.exists(result_file)) {
  df_final = readRDS(result_file)
} else {
  # Fallback simulation for CRAN servers or users without the file.
  warning(
    "Full simulation file (N=1000) not found. Running demo simulation (N=10)."
    )
  
  # 1. Light Config
  N_DEMO = 10 
  T_PTS = 2048
  SD_NOISE = 0.2
  
  grid_demo = expand.grid(
    Wavelet = c("haar", "db2", "cdf53", "cdf97", "dd4"),
    Mode = c("Offline", "Causal"),
    Method = c("hard", "soft", "semisoft"),
    Extension = c("symmetric", "periodic"), 
    stringsAsFactors = FALSE
  )
  
  res_list = list()
  
  # 2. Simplified Loop
  for (tipo in c("bumps", "doppler", "heavisine")) {
    sinal_puro = rLifting:::.generate_signal(tipo, n = T_PTS)
    
    for (i in 1:N_DEMO) {
      ruido = rnorm(T_PTS, sd = SD_NOISE)
      sinal_ruidoso = sinal_puro + ruido
      
      # Baseline
      m_base = calc_metrics(sinal_puro, sinal_ruidoso)
      res_list[[length(res_list)+1]] = data.frame(
        Sinal = tipo, Wavelet = "None", 
        Mode = "Baseline", Method = "None", Extension = "None",
        RMSE = m_base["RMSE"], SNR = m_base["SNR"], 
        MBE = m_base["MBE"]
      )
      
      # Grid
      for (j in 1:nrow(grid_demo)) {
        p = grid_demo[j, ]
        sch = lifting_scheme(p$Wavelet)
        
        if (p$Mode == "Offline") {
          proc = denoise_signal_offline(
            sinal_ruidoso, sch, 
            method=p$Method, 
            extension=p$Extension,
            levels = 3
            )
        } else {
          proc = denoise_signal_causal(
            sinal_ruidoso, sch, 
            window_size=256, method=p$Method, 
            extension=p$Extension,
            levels = 3
            )
        }
        
        m = calc_metrics(sinal_puro, proc)
        
        res_list[[length(res_list)+1]] = data.frame(
          Sinal = tipo, Wavelet = p$Wavelet, Mode = p$Mode, 
          Method = p$Method, Extension = p$Extension,
          RMSE = m["RMSE"], SNR = m["SNR"], MBE = m["MBE"]
        )
      }
    }
  }
  
  # 3. Aggregation
  df_full = do.call(rbind, res_list)
  
  df_final = df_full |>
    group_by(Sinal, Wavelet, Mode, Method, Extension) |>
    summarise(
      RMSE = mean(RMSE), 
      SNR = mean(SNR), 
      MBE = mean(MBE), 
      .groups = "drop"
    )
}
```

### The Cost of Causality

When comparing the best possible configuration for each approach (Causal, Offline, and Baseline), a clear hierarchy emerges: Non-Causal methods (which "see" the future) outperform Causal methods.
However, the optimized Causal method still offers significant gain over the noisy baseline, validating its practical utility.

```{r}
# Aggregate by BEST performance per mode
overview = df_final |>
  group_by(Sinal, Mode) |>
  summarise(
    SNR = max(SNR),
    RMSE = min(RMSE),
    .groups = 'drop'
  ) |>
  pivot_longer(
    cols = c(SNR, RMSE), 
    names_to = "Metric", 
    values_to = "Value"
  )

ggplot(overview, aes(x = Sinal, y = Value, fill = Mode)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8) +
  scale_fill_manual(values = cols_mode) +
  facet_wrap(~Metric, scales = "free_y", ncol = 1) +
  labs(
    title = "Peak Performance: SNR vs RMSE",
    subtitle = "Comparison of the best configuration found for each mode",
    y = NULL, 
    fill = NULL
  ) +
  theme_bw() +
  theme(legend.position = "top")
```

The "Cost of Causality" is defined as the performance loss (in SNR or RMSE) incurred when opting for a causal approach instead of a non-causal one due to real-time constraints.

### Smoothing vs. Reactivity

In non-causal mode, smooth and long wavelets (`CDF9/7` or `DD4`) generally outperform simpler wavelets like `haar` and `db2`.
In our causal simulations, however, we observe an interesting inversion.

```{r}
# Prepare long data
causal_perf = df_final |>
  filter(Mode == "Causal", Method == "semisoft", Extension == "symmetric") |>
  select(Sinal, Wavelet, SNR, RMSE) |>
  pivot_longer(c(SNR, RMSE), names_to = "Metric", values_to = "Value")

# Prepare baselines
baselines = df_final |> 
  filter(Mode == "Baseline") |> 
  group_by(Sinal) |> 
  summarise(
    SNR = mean(SNR),
    RMSE = mean(RMSE),
    .groups = 'drop'
  ) |>
  pivot_longer(c(SNR, RMSE), names_to = "Metric", values_to = "Base_Val")

ggplot(causal_perf, aes(x = Wavelet, y = Value)) +
  geom_bar(stat = "identity", fill = "royalblue", alpha = 0.8) +
  geom_hline(
    data = baselines, 
    aes(yintercept = Base_Val, linetype = "Baseline"), 
    color = "firebrick",
    linewidth = 0.8
  ) +
  facet_grid(Metric ~ Sinal, scales = "free_y") +
  labs(
    title = "Detailed Causal Performance",
    subtitle = "SNR (higher is better) vs RMSE (lower is better)",
    y = NULL
  ) +
  theme_bw() +
  theme(
    legend.position = "top", 
    legend.title = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

The superiority of `haar` in causal mode is due to its compact support.
Haar uses only two coefficients, so its response to a signal change is nearly instantaneous (0.5 sample delay).
Longer filters (`CDF9/7`), when calculating the current point at the window's edge, rely heavily on artificial boundary extension.
In practice, long filters "take longer" to react to peaks and abrupt changes, introducing **Phase Lag**.

### Impact of Boundary Extension

The reader might notice that we used symmetric extension above.
Depending on the wavelet configuration (and especially the extension type), causal smoothing can degrade the signal to a point where it becomes worse than the original noisy data.

The table below shows cases where the resulting SNR was lower than the baseline (Negative Gain).
Note that this predominantly occurs with `periodic` extension.
Wavelets with short filters (`haar`, `db2`) are generally immune to this.

```{r}
base_wide = df_final |>
  filter(Mode == "Baseline") |>
  group_by(Sinal) |>
  summarise(
    Base_SNR = mean(SNR),
    Base_RMSE = mean(RMSE)
  )

failures = df_final |>
  filter(Mode == "Causal") |>
  left_join(base_wide, by = "Sinal") |>
  mutate(
    Gain_dB = SNR - Base_SNR, 
    Gain_RMSE = Base_RMSE - RMSE 
  ) |>
  filter(Gain_dB < 0) |> 
  select(Sinal, Wavelet, Method, Extension, Gain_dB, Gain_RMSE) |>
  arrange(Gain_dB)

if(nrow(failures) > 0) {
  knitr::kable(
    failures, 
    digits = 4,
    caption = "Degradation Cases (SNR < Baseline)"
  )
} else {
  cat("No method performed worse than baseline on average.")
}

```

This behavior reinforces the recommendation to use **symmetric extension** as the safe default for real-time applications in `rLifting`.

### Impact of Thresholding Method

The choice of shrinkage function defines how wavelet coefficients are attenuated.

-   `hard` keeps original amplitude but increases variance.

-   `soft` ensures smoothness but introduces amplitude bias.

-   `semisoft` (*Hyperbolic*) seeks a balance.

```{r plot_thresh, fig.height=4}
comp_thresh = df_final |>
  filter(Wavelet == "cdf97", Extension == "symmetric")

ggplot(comp_thresh, aes(x = Method, y = SNR)) +
  geom_bar(stat = "identity", fill = "royalblue", alpha = 0.8) +
  facet_grid(Mode ~ Sinal) +
  labs(
    title = "Impact of Thresholding Method (CDF 9/7)",
    subtitle = "Consistency between Offline and Causal modes",
    y = "SNR (dB)",
    x = NULL
    ) +
  theme_bw()
```

The observed difference is generally small.
The best method depends more on the specific signal/wavelets characteristics.

## Conclusion

Based on this guide, we recommend the following defaults:

1.  **Prefer Offline:** If real-time processing is not required, the Offline mode offers considerably better performance.

2.  **Watch the Lag:** In real-time, smooth wavelets (`CDF97`) clean the signal well but introduce lag.
    Short wavelets (`Haar`, `DB2`) are "snappier" and often perform better in causal scenarios involving abrupt changes.

3.  **Extension Matters:** Always use `symmetric` extension for causal processing to avoid boundary artifacts that can ruin the signal at the leading edge.
